{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import ast\n",
    "\n",
    "import nltk\n",
    "import gensim\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import ngrams\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test classification dataset\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# evaluate multinomial logistic regression model\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firehouse = pd.read_csv('firehouse_with_reviews.csv', sep = ',')\n",
    "subway = pd.read_csv('subway_with_reviews.csv', sep = ',')\n",
    "jmike = pd.read_csv('jersey_mike_with_reviews.csv', sep = ',')\n",
    "jj = pd.read_csv('jimmy_johns_with_reviews.csv', sep = ',')\n",
    "potbelly = pd.read_csv('potbelly_with_reviews.csv', sep = ',')\n",
    "quiznos = pd.read_csv('quiznos_with_reviews.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firehouse.head()\n",
    "subway.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [firehouse, subway, jmike, jj, potbelly, quiznos]\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge reviews texts by business_id in df_merge\n",
    "df_merge = df.groupby(['business_id'], as_index=False).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_review = df_merge[['business_id', 'name', 'address', 'stars_x', 'text']]\n",
    "df_review.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Text Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use nltk's English stopwords.\n",
    "stopwords = nltk.corpus.stopwords.words('english') #stopwords.append(\"n't\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the regular expression library\n",
    "import re\n",
    "\n",
    "# Remove punctuation\n",
    "df_review['text_processed'] = \\\n",
    "df_review['text'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "# Convert the titles to lowercase\n",
    "df_review['text_processed'] = \\\n",
    "df_review['text_processed'].map(lambda x: x.lower())\n",
    "# Print out the first rows of papers\n",
    "df_review['text_processed'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_review = []\n",
    "for sent in df_review['text_processed']:\n",
    "    merge_review.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THIS CODE FOR DATA FRAME\n",
    "vect = TfidfVectorizer(ngram_range = (1, 2))\n",
    "tfidf_matrix = vect.fit_transform(merge_review)\n",
    "print(tfidf_matrix.shape)\n",
    "df = pd.DataFrame(tfidf_matrix.toarray(), columns = vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "# sentence = input(\"Enter the sentence: \")\n",
    "# n = int(input(\"Enter the value of n: \"))\n",
    "lst_grams = []\n",
    "sentence = 'My husband and I ordered sandwiches for pickup today, which we do a couple times a month. His pastrami was well-made with a good portion of deli meat. My tuna... well at first I thought they entirely forgot the tuna! Pulled it apart to find a tiny spoonful on each half-- absolutely laughable amount of filling! I order this sandwich regularly and it\\'s NEVER like that. He took it back and asked for a remake,l. The assistant managers said \"it\\'s our portion size\", and never apologized or offered either a refund or a remake. So $7 for a teaspoon of tuna, and apathetic response from the employees... you ARE KIDDING ME!! Customer service standards and quality need an overhaul in this location.'\n",
    "n_grams = ngrams(sentence.split(), 2)\n",
    "for grams in n_grams:\n",
    "    lst_bigrams.append(grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With review sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ','.join(merge_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split reviews corpus into bigrams\n",
    "from nltk import ngrams\n",
    "lst_bigrams = []\n",
    "n_grams = ngrams(corpus.split(), 2)\n",
    "for grams in n_grams:\n",
    "    lst_bigrams.append(grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting bigram counts\n",
    "bigram_frequency = {}\n",
    "for char in lst_bigrams:\n",
    "    if char in bigram_frequency:\n",
    "        bigram_frequency[char] += 1\n",
    "    else:\n",
    "        bigram_frequency[char] = 1\n",
    "print(bigram_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sort by descending count\n",
    "bigram_frequency_sorted = sorted(bigram_frequency.items(), \n",
    "                              key = lambda kv: kv[1], \n",
    "                              reverse = True)\n",
    "type(bigram_frequency_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_df = pd.DataFrame(bigram_frequency_sorted)\n",
    "bigram_df.columns = ['bigrams', 'counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_df.to_csv('bigram_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import classification_report\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# merge tf-idf and business data\n",
    "# df = tf-idf matrix\n",
    "pd.concat([df_review, df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLR choosing single words and n-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df[[\"bread\", \"staff\", \"beef\", \"lunch\", \"cheese\", \"fresh\", \"fast\", \n",
    "                \"flatbread\", \"teriyaki\", 'meatball', 'italian', 'tomato', 'steak']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_select\n",
    "y = df_review['stars_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=train_samples, test_size= 834 - train_samples, random_state = 11) # 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sq = model.score(x, y)\n",
    "r_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"intercept: {model.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"coefficients: {model.coef_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = np.around(yhat, decimals = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = yhat.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy for MLR\n",
    "score = accuracy_score(yhat, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prep data train & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = 667\n",
    "X = df_select\n",
    "y = df_review['stars_x']\n",
    "\n",
    "# type_of_target(y)\n",
    "# label_encoder = LabelEncoder()\n",
    "# y = label_encoder.fit_transform(y)\n",
    "y = y.astype('int')\n",
    "type_of_target(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=train_samples, test_size= 834 - train_samples, random_state = 11) # 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model accuracy with CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define the multinomial logistic regression model with a default penalty\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='l2', \n",
    "                           C=1.0, max_iter = 1000000)\n",
    "\n",
    "# define the model evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report the model performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "result = model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test # test data response array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = X_test# .iloc[0:1, :] # first row of test data\n",
    "# predict a multinomial probability distribution\n",
    "p = model.predict_proba(row)\n",
    "# summarize the predicted probabilities\n",
    "print(p) # 'Predicted Probabilities: %s' %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# predict the class label\n",
    "yhat = model.predict(row)\n",
    "print(yhat) # predicted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing beta coefficients\n",
    "print(result.intercept_)\n",
    "print(result.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives coefficients chart with features\n",
    "summary = pd.DataFrame(zip(X.columns, np.transpose(result.coef_.tolist()[0])), \n",
    "                       columns=['features', 'coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set accuracy \n",
    "score = accuracy_score(yhat, y_test)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
